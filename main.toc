\contentsline {chapter}{\numberline {1}Introduction}{3}{Doc-Start}%
\contentsline {section}{\numberline {1.1}What is machine learning}{3}{section.1.1}%
\contentsline {section}{\numberline {1.2}What is deep learning?}{3}{section.1.2}%
\babel@toc {ngerman}{}
\contentsline {subsection}{\numberline {1.2.1}What is a neural network (NN)}{5}{subsection.1.2.1}%
\contentsline {section}{\numberline {1.3}Examples for Deep Learning}{5}{section.1.3}%
\contentsline {chapter}{\numberline {2}Tools for Deep Learning}{5}{section.1.3}%
\contentsline {section}{\numberline {2.1}Software}{5}{section.2.1}%
\contentsline {section}{\numberline {2.2}Hardware}{5}{section.2.2}%
\contentsline {section}{\numberline {2.3}Datasets}{5}{section.2.3}%
\contentsline {chapter}{\numberline {3}Machine learning basics}{7}{section.2.3}%
\contentsline {section}{\numberline {3.1}Linear Algebra}{7}{section.3.1}%
\contentsline {section}{\numberline {3.2}Random variable and probability distribution}{7}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}One random vector}{7}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}Multiple random vectors}{9}{subsection.3.2.2}%
\contentsline {subsection}{\numberline {3.2.3}Kernel based density estimation }{11}{subsection.3.2.3}%
\contentsline {section}{\numberline {3.3}Kullback-Leibler divergence and cross entropy }{11}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}E3.5 KLD between normal and Laplace distribution }{13}{subsection.3.3.1}%
\contentsline {section}{\numberline {3.4}Probabilistic framework for machine learning}{13}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}Role of a NN }{17}{subsection.3.4.1}%
\contentsline {chapter}{\numberline {4}Dense Neural Networks }{19}{subsection.3.4.1}%
\contentsline {section}{\numberline {4.1}Fully connected neural networks - Neuron}{19}{section.4.1}%
\contentsline {section}{\numberline {4.2}Chapter 4.2 Layer of Nurons}{19}{section.4.2}%
\contentsline {section}{\numberline {4.3}Feedforward neural network}{21}{section.4.3}%
\contentsline {section}{\numberline {4.4}Activation function}{21}{section.4.4}%
\contentsline {subsection}{\numberline {4.4.1}Sigmoid activation function}{23}{subsection.4.4.1}%
\contentsline {subsection}{\numberline {4.4.2}hyperbolic tangent activation function }{23}{subsection.4.4.2}%
\contentsline {subsection}{\numberline {4.4.3}rectifier linear unit(ReLU}{25}{subsection.4.4.3}%
\contentsline {subsection}{\numberline {4.4.4}Softmax activatoin function(classification problem)}{25}{subsection.4.4.4}%
\contentsline {subsection}{\numberline {4.4.5}Special case c=2, binary classification problem}{25}{subsection.4.4.5}%
\contentsline {section}{\numberline {4.5}Universal approximation }{25}{section.4.5}%
\contentsline {subsection}{\numberline {4.5.1}E4.3 Regression with 1 hidden layer}{27}{subsection.4.5.1}%
\contentsline {section}{\numberline {4.6}Loss and cost function}{27}{section.4.6}%
\contentsline {subsection}{\numberline {4.6.1}Regression Problem}{27}{subsection.4.6.1}%
\contentsline {subsection}{\numberline {4.6.2}Classification}{29}{subsection.4.6.2}%
\contentsline {subsection}{\numberline {4.6.3}Semantic segmentation }{29}{subsection.4.6.3}%
\contentsline {section}{\numberline {4.7}Training}{31}{section.4.7}%
\contentsline {subsection}{\numberline {4.7.1}Chainrule of derivative (back propagation)}{31}{subsection.4.7.1}%
\contentsline {section}{\numberline {4.8}4.8 Implementation of DNN's in Python}{33}{section.4.8}%
\contentsline {chapter}{\numberline {5}Advanced optimization techniques}{35}{section.4.8}%
\contentsline {section}{\numberline {5.1}Difficulties in optimization }{35}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}E5.1: sigmoid vs. ReLU}{37}{subsection.5.1.1}%
\contentsline {section}{\numberline {5.2}Momentum method}{37}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}Nesterov Momentum}{37}{subsection.5.2.1}%
\contentsline {section}{\numberline {5.3}5.3 Learning rate schedule}{37}{section.5.3}%
