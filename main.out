\BOOKMARK [0][-]{Doc-Start}{Introduction}{}% 1
\BOOKMARK [1][-]{section.1.1}{Overview}{Doc-Start}% 2
\BOOKMARK [1][-]{section.1.2}{Chapter 1.1 - What is machine learning}{Doc-Start}% 3
\BOOKMARK [1][-]{section.1.3}{Chapter 1.2 - What is deep learning}{Doc-Start}% 4
\BOOKMARK [2][-]{subsection.1.3.1}{What is a neural network \(NN\)}{section.1.3}% 5
\BOOKMARK [1][-]{section.1.4}{Chapter 1.3 - Examples for Deep Learning}{Doc-Start}% 6
\BOOKMARK [0][-]{section.1.4}{Tools for Deep Learning}{}% 7
\BOOKMARK [1][-]{section.2.1}{Datasets}{section.1.4}% 8
\BOOKMARK [0][-]{section.2.1}{Machine learning basics}{}% 9
\BOOKMARK [1][-]{section.3.1}{Linear Algebra}{section.2.1}% 10
\BOOKMARK [1][-]{section.3.2}{Chapter 3.2 Random variable and probability distribution}{section.2.1}% 11
\BOOKMARK [2][-]{subsection.3.2.1}{3.2.1 One random vector}{section.3.2}% 12
\BOOKMARK [1][-]{section.3.3}{Chapter 3.3 - Multiple random vectors}{section.2.1}% 13
\BOOKMARK [2][-]{subsection.3.3.1}{ Chapter 3.2.3 - Kernel basaed density estimation }{section.3.3}% 14
\BOOKMARK [1][-]{section.3.4}{Chapter 3.4 Kullback-Leibler divergence and cross entropy }{section.2.1}% 15
\BOOKMARK [2][-]{subsection.3.4.1}{E3.5 KLD between normal and Laplace distribution }{section.3.4}% 16
\BOOKMARK [1][-]{section.3.5}{Chapter 3.5 Probabilistic framework }{section.2.1}% 17
\BOOKMARK [2][-]{subsection.3.5.1}{Role of a NN }{section.3.5}% 18
\BOOKMARK [0][-]{subsection.3.5.1}{Dense Neural Networks }{}% 19
\BOOKMARK [1][-]{subsection.4.0.1}{4.1 Fully connected neural networks - Neuron}{subsection.3.5.1}% 20
\BOOKMARK [2][-]{subsection.4.0.2}{Chapter 4.2 Layer of Nurons}{subsection.4.0.1}% 21
\BOOKMARK [1][-]{section.4.1}{4.3 Feedforward neural network}{subsection.3.5.1}% 22
\BOOKMARK [0][-]{figure.4.5}{Dense Neural Networks}{}% 23
\BOOKMARK [1][-]{section.5.1}{Activation function}{figure.4.5}% 24
\BOOKMARK [2][-]{subsection.5.1.1}{Sigmoid activation function}{section.5.1}% 25
\BOOKMARK [2][-]{subsection.5.1.2}{hyperbolic tangent activation function }{section.5.1}% 26
\BOOKMARK [2][-]{subsection.5.1.3}{rectifier linear unit\(ReLU}{section.5.1}% 27
\BOOKMARK [2][-]{subsection.5.1.4}{Softmax activatoin function\(classification problem\)}{section.5.1}% 28
\BOOKMARK [1][-]{section.5.2}{Special case c=2, binary classification problem}{figure.4.5}% 29
\BOOKMARK [1][-]{section.5.3}{Chapter 4.5 Universal approximation }{figure.4.5}% 30
\BOOKMARK [2][-]{subsection.5.3.1}{E4.3 Regression with 1 hidden layer}{section.5.3}% 31
\BOOKMARK [1][-]{section.5.4}{Chapter 4.4 - 4.6 Loss and cost function}{figure.4.5}% 32
\BOOKMARK [2][-]{subsection.5.4.1}{4.6.3 Semantic segmentation }{section.5.4}% 33
\BOOKMARK [1][-]{section.5.5}{Chapter 4.7 Training}{figure.4.5}% 34
